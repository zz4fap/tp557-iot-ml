{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LXOB7WZMEyN"
   },
   "source": [
    "# Exercício sobre regressão com DNNs\n",
    "\n",
    "Explique o(s) motivo(s) do valor predito (i.e., da inferência feita) pela DNN do exemplo visto em sala de aula não ser exatamente o valor que esperávamos?\n",
    "\n",
    "O que pode ser feito para melhorar a precisão das inferências feitas pela DNN?\n",
    "\n",
    "Implemente todas as modificações que você achar necessarias e aprensente os resultados.\n",
    "\n",
    "**Descreva cada uma das mudanças feitas e as justifique.**\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ Você pode querer alterar o otimizador ou definir outros valores para os parâmetros do otimizador atual, para isso, consulte a documentação sobre [otimizadores](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental)\n",
    "+ Você pode querer também aumentar o conjunto de treinamento, para isso, lembre-se que a função original, ou seja, aquela que gerou os dados que estamos usando para o treinamento do modelo, é dada por $y = -1 + 2x$.\n",
    "+ Pense sobre o número de épocas que usamos no exemplo. Você acha que 500 épocas é um valor pequeno ou grande para o treinamento de um modelo que resolva um problema tão simples quanto esse apresentado no exemplo? Lembre-se que no exemplo, cada época de treinamento corresponde ao processo de (i) iniciar os pesos aleatóriamente (i.e., palpite inicial), (ii) calcular o erro, (iii) calcular o vetor gradiente do erro, (iv) atualiar os pesos dando um **passo** na direção apontada pelo gradiente. Reflita sobre o tamanho desse passo, ele pode interferir na precisão do modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9_MLEnwMGLw"
   },
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCm3x_4F8bvg",
    "outputId": "16977961-46ca-4ee3-a5a7-cda50b4d1c52"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFwzjVOyMYj0"
   },
   "source": [
    "### Definindo o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4i0p7efDX2M"
   },
   "outputs": [],
   "source": [
    "x = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "y = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVMr79-_MiII"
   },
   "source": [
    "### Definindo a rede neural densa\n",
    "\n",
    "Define uma rede neural densa com um neurônio e entrada com uma dimensão.\n",
    "\n",
    "Para mais informações sobre as classes e funções do TF, acesse: https://www.tensorflow.org/api_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLqOZPfC8gfb"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprimindo um resumo da arquitetura do modelo\n",
    "\n",
    "+ O método `summary` imprime uma descrição da arquitetura do modelo, mostrando a disposição das camadas e o número total de parâmetros treináveis e não treináveis.\n",
    "    + Parâmetros não treináveis são aqueles que não são atualizados durante o treinamento do modelo.\n",
    "\n",
    "+ Ele exibe as seguintes informações:\n",
    "    + O nome de cada camada (que é gerado automaticamente, a menos o definamos ao criar a camada), \n",
    "    + Seu formato de saída (`None` significa que o tamanho do mini-batch pode ser qualquer um) e \n",
    "    + Seu número de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_iL7WpMNCWp",
    "outputId": "7408876e-fae4-484e-e9d5-e17a17defbf0"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsF5wyWpO3fP"
   },
   "source": [
    "### Inspecionando os pesos iniciais do modelo\n",
    "\n",
    "A inicialização dos pesos é crucial para o bom treinamento de um modelo, pois ela\n",
    "\n",
    "+ Acelera a convergência (i.e., o aprendizado do modelo),\n",
    "+ Evita problemas de explosão e desaparecimento do gradiente.\n",
    "    + Explosão: os gradientes se tornam tão grandes e, consequentemente, os pesos também, levando a divergência do modelo.\n",
    "    + Desaparecimento: os gradientes se tornam extremamente pequenos e, consequentemente, as atualizações dos pesos também, resultando em treinamento (i.e., aprendizado) lento ou mesmo estagnação.\n",
    "\n",
    "Por padrão, os pesos do modelo são inicializados pela classe `Dense` da seguinte forma:\n",
    "\n",
    "+ O parâmetro `kernel_initializer` define como os pesos sinápticos ($w$) são inicializados => Por padrão, usa-se a inicialização `glorot_uniform` (também chamadade **Xavier**)\n",
    "\n",
    "    + Incializa-se os pesos usando amostras retiradas de uma distribuição uniforme com limites: `[-limit, limit]`, onde \n",
    "    $$\\text{limit} = \\sqrt{\\frac{6}{(\\text{fan}_{\\text{in}} + \\text{fan}_{\\text{out}})}}$$\n",
    "    + $\\text{fan}_{\\text{in}}$ é igual ao número de neurônios da camada anterior e $\\text{fan}_{\\text{out}}$ é igual ao número de neurônios nessa camada sendo configurada.\n",
    "\n",
    "+ O parâmetro `bias_initializer` define como os pesos de bias ($b$) são inicializados => Por padrão, todos os valores inciais dos pesos de bias são zerados (`zeros`).\n",
    "\n",
    "\n",
    "Existem outras formas de se inicializar os pesos, para mais informações, acesse: [Initializers](https://keras.io/api/layers/initializers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foCw7XZhNU8i",
    "outputId": "f157801e-5978-4f1b-e223-45148c2ea254"
   },
   "outputs": [],
   "source": [
    "# Retorna uma lista com todos os pesos.\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Acessando o peso sináptico e o de bias do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7Z5OEcDOAEy",
    "outputId": "7b3a9bb8-b626-4935-e8b6-a8473f27a809"
   },
   "outputs": [],
   "source": [
    "print(\"w = \", model.get_weights()[0][0][0])\n",
    "print(\"b  = \", model.get_weights()[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaqMbbf5Mos8"
   },
   "source": [
    "### Compilando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos como **otimizador** o gradiente descendente estocástico e como **função de erro** o erro quadrático médio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUyEy3iMDKy3"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo uma predição com o modelo inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L98RvpdusUYf",
    "outputId": "47f8aa5e-aa50-4675-f92b-7090a62b01b0"
   },
   "outputs": [],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDHKYghlNBLh"
   },
   "source": [
    "### Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UorrgCYTETFn",
    "outputId": "632d8a9a-9755-4020-af7c-611a8ee4b5bb"
   },
   "outputs": [],
   "source": [
    "# Ajusta o modelo aos dados (também conhecido como treinar o modelo)\n",
    "history = model.fit(x, y, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9od0MhXAXA5Z"
   },
   "outputs": [],
   "source": [
    "model.save('my_first_trained_dnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oli3anGPV4z"
   },
   "source": [
    "### Testando o modelo\n",
    "\n",
    "Prevendo a saída de um novo dado (inédito) de entrada (também conhecido como **inferência**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nidfsvPCEWlE",
    "outputId": "7e6b9623-11f1-4ec3-e3ef-8d7ca9bf2e7f"
   },
   "outputs": [],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93itssi3PgsX"
   },
   "source": [
    "### Inspecionando os pesos do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Knk6L2pzPjo_",
    "outputId": "4ff9b70b-afb8-487f-abbf-af0d5a58c584"
   },
   "outputs": [],
   "source": [
    "print(\"w = \", model.get_weights()[0][0][0])\n",
    "print(\"b  = \", model.get_weights()[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos inspecionar o modelo de forma visual usando a aplicação web chamada de [Netron](https://netron.app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando o histórico de erros ao longo das épocas de treinamento\n",
    "\n",
    "O objeto da classe `History` possui um atributo chamado de `history`, que é um dicionário com os valores do erro ao longo das épocas de treinamento.\n",
    "\n",
    "Esse dicionário pode conter outras medidas feitas longo do treinamento e teste do modelo, para isso, basta especificar o que se quer medir através do parâmetro `metrics` do método `compile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FU9DgCReU01e",
    "outputId": "2b6bc781-9a48-4391-97f9-c975e2a2b03b"
   },
   "outputs": [],
   "source": [
    "type(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z83TiMLeU8hk",
    "outputId": "d7625e92-9067-4b8f-e511-7731a0f8ee46"
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "vpdU7AZbT0YJ",
    "outputId": "cbf03ff9-a745-4e39-c33f-b2d809f5a1d0"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
