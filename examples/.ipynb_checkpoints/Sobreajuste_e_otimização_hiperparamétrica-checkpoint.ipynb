{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21HL_zD-Y2Ga"
   },
   "source": [
    "# Sobreajuste e otimização hiperparamétrica\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nov-CJlfY2Gn"
   },
   "source": [
    "## Baixando e normalizando os dados.\n",
    "\n",
    "Utilizaremos a base de dados conhecida como CIFAR10. Ela possui 60.000 imagens **coloridas** com dimensão $32 \\times 32 \\times 3$, ou seja, elas têm 3 dimensões (ou canais), uma para cada uma das três cores, RGB (vermelho, verde e azul).\n",
    "\n",
    "Usaremos 50.000 imagens para treinamento e 10.000 imagens para validação. As imagens pertencem a 10 classes, as quais são listadas abaixo.\n",
    "\n",
    "| Rótulo |  Descrição |\n",
    "|:------:|:----------:|\n",
    "|    0   |  airplane  |\n",
    "|    1   | automobile |\n",
    "|    2   |    bird    |\n",
    "|    3   |     cat    |\n",
    "|    4   |    deer    |\n",
    "|    5   |     dog    |\n",
    "|    6   |    frog    |\n",
    "|    7   |    horse   |\n",
    "|    8   |    ship    |\n",
    "|    9   |    truck   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syIYbkj-Y2Go",
    "outputId": "a7ded667-c683-48a1-989b-0883f8d86f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Bibliotecas Auxiliares\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Instalando o KerasTuner.\n",
    "!pip install keras-tuner --upgrade\n",
    "\n",
    "# Importanda a biblioteca KerasTuner.\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Download the dataset.\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Reshaping the label arrays.\n",
    "train_labels = train_labels.reshape(-1,)\n",
    "test_labels = test_labels.reshape(-1,)\n",
    "\n",
    "# Defining the class names.\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Scaling.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6YN2FyOY2Gu"
   },
   "source": [
    "## Criando, configurando e treinando uma rede neural convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuavsTHqY2G5"
   },
   "outputs": [],
   "source": [
    "# Define VGG model.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=128,kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=1024, activation='relu', kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu', kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the defined model.\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the VGG model.\n",
    "history = model.fit(train_images, train_labels, batch_size=64, validation_data=(test_images, test_labels), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4l28-IXY2HG"
   },
   "source": [
    "## Plotando os erros e acurácias de treinamento e validação em função das épocas de treinamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMiASJPHY2HH"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Época', fontsize=14)\n",
    "plt.legend(['Train', 'Val'], fontsize=14)\n",
    "plt.title('Loss', fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-tkZEA3uMYn"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('Época', fontsize=14)\n",
    "plt.legend(['Train', 'Val'], fontsize=14)\n",
    "plt.title('Acurácia', fontsize=14)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKH9wisKvIUz"
   },
   "source": [
    "## Otimização hiperparamétrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GvzZ0ndOe4Q-"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    # Cria o modelo sequêncial.\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Number of convolutional layers.\n",
    "    numOfConvLayers = hp.Choice('numOfConvLayers', range(1,7))\n",
    "\n",
    "    numOfDenseLayers = hp.Choice('numOfDenseLayers', range(0,3))\n",
    "\n",
    "    filterSize = hp.Choice('filterSize', [8, 16, 32, 64])\n",
    "\n",
    "    activation = hp.Choice('activation', ['relu', 'logistic', 'tanh'])\n",
    "\n",
    "    optimizer = hp.Choice('optimizer', ['sgd', 'adam', 'nadam'])\n",
    "\n",
    "    # Adiciona camadas convolucionais.\n",
    "    for i in range(numOfConvLayers):\n",
    "        if(i==0):\n",
    "            model.add(tf.keras.layers.Conv2D(filters=filterSize, kernel_size=(3, 3), activation=activation, padding='same', input_shape=(32, 32, 3)))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Conv2D(filters=filterSize*(i+1), kernel_size=(3, 3), activation=activation, padding='same'))\n",
    "        if(i % 2 != 0):\n",
    "            model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Adiciona camada de achatamento.\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # Adiciona camadas densas.\n",
    "    for i in range(numOfDenseLayers):\n",
    "        numberOfNodes = hp.Choice('numberOfNodes', [1024, 512, 256, 128, 64])\n",
    "        model.add(tf.keras.layers.Dense(units=numberOfNodes//(i+1), activation=activation, kernel_initializer='he_uniform'))\n",
    "\n",
    "    # Adiciona a camada de saída.\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "    # Compile the defined model.\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Retorna o modelo.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MkUGeY5ue4Q-"
   },
   "outputs": [],
   "source": [
    "# Instanciando um objeto da classe BayesianOptimization.\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_loss'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U9NupIoDe4Q-",
    "outputId": "80a1e9a4-03de-4d46-8fe9-c662d88e0319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 00s]\n",
      "\n",
      "Best val_loss So Far: None\n",
      "Total elapsed time: 00h 00m 00s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "1                 |3                 |numOfConvLayers\n",
      "1                 |1                 |numOfDenseLayers\n",
      "32                |8                 |filterSize\n",
      "tanh              |logistic          |activation\n",
      "sgd               |adam              |optimizer\n",
      "\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    batch_size=64,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAsm6WVie4Q-"
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
